{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning directory .\n",
      "Total 2 files, 1 directories removed.\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "!pyclean ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lalala import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spacecraft_id</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23c7f89d00006caee536a22e5807de95</th>\n",
       "      <td>5</td>\n",
       "      <td>994</td>\n",
       "      <td>596</td>\n",
       "      <td>1079</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  spacecraft_id  xmin  ymin  xmax  ymax\n",
       "image_id                                                               \n",
       "23c7f89d00006caee536a22e5807de95              5   994   596  1079   705"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_bg_meta = pd.read_csv(os.path.join(DATA_DIRECTORY,\"no_background\",\"no_background.csv\"),index_col=\"image_id\")\n",
    "no_bg_meta.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacecraft_5 = [os.path.join(DATA_DIRECTORY,\"no_background\", \"images\", i) + \".png\" for i in no_bg_meta[no_bg_meta.spacecraft_id == 5].index]\n",
    "spacecraft_5_bbox = [[k[\"xmin\"], k[\"ymin\"], k[\"xmax\"], k[\"ymax\"]] for i,k in no_bg_meta.iterrows()if k[\"spacecraft_id\"] == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "space5 = dataset_flow(spacecraft_5, spacecraft_5_bbox, batch_size=2)\n",
    "space5\n",
    "image_sample, bbox_sample = next(space5.__iter__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backbone, no need to train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Backbone and using the size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Backbone and using the size\n",
    "backbone = resnet_fpn((224,224,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create the FPN elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    }
   ],
   "source": [
    "fpn_feature_maps = backbone.predict(image_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 224, 224, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input the FPN into RPN and get the probability and bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 56, 56, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpn_feature_maps[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_anchors(fpn_feature_maps, ratios = [0.5, 1., 2.], scales = [2 ** (x/3) for x in range(3)], feature_size =[56., 28., 14., 7., 4.]):\n",
    "    anchors_all = []\n",
    "    for ix, fpn_feature_map in enumerate(fpn_feature_maps):\n",
    "        base_size = fpn_feature_map.shape[1]\n",
    "        anchors = []\n",
    "        for i in range(fpn_feature_map.shape[-1]):\n",
    "            anchors1 = []\n",
    "            for scale in scales:\n",
    "                for ratio in ratios:\n",
    "                    # Calculate anchor dimensions based on scale and ratio\n",
    "                    anchor_height = base_size * scale * np.sqrt(ratio) /2\n",
    "                    anchor_width = base_size * scale / np.sqrt(ratio) /2\n",
    "                    \n",
    "                    # Generate anchors across the feature map\n",
    "                    \n",
    "                    x = feature_size[ix]\n",
    "                    y = feature_size[ix]\n",
    "                    center_x = (x + 0.5) /2\n",
    "                    center_y = (y + 0.5) /2\n",
    "                    anchors1.append([\n",
    "                        int(max(center_x - anchor_width / 2, 0.)),\n",
    "                        int(max(center_y - anchor_height / 2, 0.)),\n",
    "                        int(min(center_x + anchor_width / 2, x)),\n",
    "                        int(min(center_y + anchor_height / 2, x)),\n",
    "                    ])\n",
    "            anchors.append(anchors1)\n",
    "    \n",
    "        anchors_all.append(anchors)\n",
    "\n",
    "    return np.array(anchors_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = generate_anchors(fpn_feature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 56)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpn_feature_maps[0][0,:,:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 16, 9, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor = anchors[0, 1, 1, :]\n",
    "fpn_feature_maps[1][0,:,:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 14, 42, 42])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_regions_from_feature_map(feature_map, anchors):\n",
    "    crops = []\n",
    "    for i in range(anchors.shape[0]): #5 # Iterate through all the anchors\n",
    "        for j in range(anchors.shape[1]): # 256   # Iterate through each of the 9 bboxes for the anchor\n",
    "            for k in range(anchors.shape[2]):   # 9\n",
    "                anchor = anchors[i, j, k, :]\n",
    "                crop = tf.image.crop_to_bounding_box(tf.expand_dims(feature_map[i][0,:,:,j], -1),\n",
    "                                                    offset_height=anchor[0],\n",
    "                                                    offset_width=anchor[1],\n",
    "                                                    target_height=anchor[2] - anchor[0],\n",
    "                                                    target_width=anchor[3] - anchor[1])\n",
    "                crop = np.squeeze(crop, axis=-1)\n",
    "                crops.append(crop)\n",
    "    return crops\n",
    "\n",
    "# Adjust anchors if necessary to fit your specific scenario\n",
    "cropped_regions = crop_regions_from_feature_map(fpn_feature_maps, anchors)\n",
    "#keep in mind that the array has different shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoI Align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cropped_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi_align(cropped_regions):\n",
    "    # Normalize proposals from [0, 1] to feature map scale\n",
    "    pooled_list = []\n",
    "    for cropped_region in cropped_regions:\n",
    "        cropped_region = tf.expand_dims(cropped_region, axis = -1)\n",
    "        resized_data = tf.image.resize(cropped_region, [224, 224], method=tf.image.ResizeMethod.BILINEAR)\n",
    "        pooled_list.append(resized_data)\n",
    "        \n",
    "    return tf.concat(pooled_list, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "roiali = roi_align(cropped_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([224, 224, 720])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roiali.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a big data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacecraft_5 = [os.path.join(DATA_DIRECTORY,\"no_background\", \"images\", i) + \".png\" for i in no_bg_meta[no_bg_meta.spacecraft_id == 5].index]\n",
    "spacecraft_5_bbox = [[k[\"xmin\"], k[\"ymin\"], k[\"xmax\"], k[\"ymax\"]] for i,k in no_bg_meta.iterrows()if k[\"spacecraft_id\"] == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_flow(image_path : list, bbox : list, batch_size : int):\n",
    "    bbox = [[i[0]/1280*224,i[1]/1024*224,i[2]/1280*224,i[3]/1024*224] for i in bbox]\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_path, bbox))\n",
    "    #<TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(4,), dtype=tf.int32, name=None))>\n",
    "    dataset = dataset.map(load_image_and_labels).batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three models for Computer Vision\n",
    "1. Mask Using Unet\n",
    "2. BBOX using CNN + FC\n",
    "3. Classification using CNN + FC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfapi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
